# -*- coding: utf-8 -*-
"""modelling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xmZ21LUejbGgZLIdXrsFDjuVUJtJoPmq
"""

!pip install mlflow

!pip install dagshub

import os
import sys
import argparse
import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import time
import warnings

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE

import mlflow
from dagshub import init

# Cegah warning
warnings.filterwarnings("ignore")

# ------------------------------------------
# Argument Parser
# ------------------------------------------
def get_args():
    if __name__ == "__main__" and not hasattr(sys, 'ps1'):
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", type=str, default="winequality_red_preprocessed.csv", help="Path to preprocessed dataset CSV")
        return parser.parse_args()
    else:
        class Args: pass
        args = Args()
        args.data_path = "winequality_red_preprocessed.csv"
        return args

args = get_args()

# ------------------------------------------
# Init MLflow & DagsHub
# ------------------------------------------
init(repo_owner="hubbiy18", repo_name="Eksperimen_SML_Febie-Elfaladonna", mlflow=True)
mlflow.set_experiment("wine_quality_binary_xgb")

# ------------------------------------------
# Load data
# ------------------------------------------
df = pd.read_csv(args.data_path)
df = df[df["quality"].isin([5, 6])]

le = LabelEncoder()
df["quality_enc"] = le.fit_transform(df["quality"])
label_mapping = {str(k): int(v) for k, v in zip(le.classes_, le.transform(le.classes_))}

with open("label_classes.json", "w") as f:
    json.dump(label_mapping, f)

X = df.drop(columns=["quality", "quality_enc"])
y = df["quality_enc"]

# Train-Test Split + SMOTE
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)

# ------------------------------------------
# Model Training
# ------------------------------------------
param_grid = {
    "max_depth": [3, 5],
    "learning_rate": [0.1, 0.01],
    "n_estimators": [100, 150],
    "subsample": [0.8]
}

xgb = XGBClassifier(objective="binary:logistic", eval_metric="logloss", use_label_encoder=False, verbosity=0)

grid = GridSearchCV(xgb, param_grid, cv=3, scoring="f1", verbose=1, n_jobs=-1)

start_time = time.time()
grid.fit(X_train, y_train)
training_time = time.time() - start_time

best_model = grid.best_estimator_

# ------------------------------------------
# Evaluation
# ------------------------------------------
y_prob = best_model.predict_proba(X_test)[:, 1]
y_pred = (y_prob >= 0.5).astype(int)

acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
cm = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred, target_names=le.classes_, output_dict=True)

# ------------------------------------------
# MLflow Logging
# ------------------------------------------
with mlflow.start_run():
    mlflow.log_params(grid.best_params_)
    mlflow.log_metric("accuracy", acc)
    mlflow.log_metric("f1_score", f1)
    mlflow.log_metric("training_time", training_time)

    # Save model & label
    joblib.dump(best_model, "model.pkl")
    mlflow.log_artifact("model.pkl")
    mlflow.log_artifact("label_classes.json")

    # Confusion matrix
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=le.classes_, yticklabels=le.classes_)
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.title("Confusion Matrix")
    plt.tight_layout()
    plt.savefig("confusion_matrix.png")
    mlflow.log_artifact("confusion_matrix.png")
    plt.close()

    # Classification report
    report_str_keys = {str(k): v for k, v in report.items()}
    with open("classification_report.json", "w") as f:
        json.dump(report_str_keys, f, indent=4)
    mlflow.log_artifact("classification_report.json")

print(f"âœ… Training selesai! Accuracy: {acc:.4f}, F1: {f1:.4f}")